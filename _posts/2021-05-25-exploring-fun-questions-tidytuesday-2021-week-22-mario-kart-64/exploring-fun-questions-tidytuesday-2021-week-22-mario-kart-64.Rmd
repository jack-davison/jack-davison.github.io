---
title: "Exploring Fun Questions (TidyTuesday 2021 Week 22: Mario Kart 64)"
description: |
  Answering data questions posed by this week's TidyTuesday using the Tidyverse.
categories:
  - tidytuesday
author:
  - name: Jack Davison
date: 05-25-2021
output:
  distill::distill_article:
    self_contained: false
    code_folding: true
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  fig.align = "center"
  )
library(tidyverse)
```

# Purpose

This week's TidyTuesday comes from [Benedickt Claus](https://github.com/benediktclaus), and is all about Mario Kart 64 Speedrunning! Benedickt has also provided a set of *"fun questions to explore"*, so I thought I'd write up my answers. If you're just starting out using R, it might be a good idea to give the questions a go yourself and then come back here to compare approaches!

# The Data

Let's start by reading in the data and giving it a little look over.

```{r}
tt = tidytuesdayR::tt_load("2021-05-25")

drivers = tt$drivers
records = tt$records

```

There are two datasets. Let's `glimpse` them to see what we're working with.

First, the *drivers* data. This is the data about the players - their name (or online handle), their overall leaderboard position, their total number of world records, their records per year, and their nationality.

```{r}
glimpse(drivers)
```

The metadata just describes the *records* column as "the number of world records". I expect this to be per year and to sum to the *total* column, so let's double check that this is true by using `group_by`, `summarise` and `count`. Our *flag* column checks that the *total* column is equal to the sum of the *records* column, and when we `count` it we see only `TRUE` values. My assumption checks out, and there's nothing weird going on in the data!

```{r}
drivers %>% 
  group_by(player) %>% 
  summarise(total = total[1], 
            total_calc = sum(records, na.rm = T),
            flag = total == total_calc) %>%
  count(flag)
```

The second dataset is the *records* data, which details the number of world records per track, record type (single- or three-lap), whether a shortcut was used, which system was used (NTSC or PAL), the date of the record, the time it took and how long the record stood for.

```{r}
glimpse(records)
```

# "Fun Questions to Explore"

Let's now get stuck in with the questions provided by Benedikt! You can find these at the end of this week's README.

## How did the world records develop over time?

This is a very open question to start with, and I think that the best way to explore it with a visualisation. Let's plot a graph using `{ggplot2}`. I'm going to `filter` for just the three-lap, no short-cut runs to start with. Interestingly, they all have very similar shapes - a rapid decrease in lap time in the pre-2000s and then a much more gentle decrease since then. This makes a level of intuitive sense - once the big secrets and techniques have been discovered, you're only going to be able to shave increasingly small amounts of time off the laps through optimising what's already being done.

```{r fig.width=10, fig.height=8, fig.cap="The evolution of three-lap, no shortcut records for Mario Kart 64."}
records %>%
  filter(type == "Three Lap", shortcut == "No") %>%
  ggplot(aes(x = date, y = time)) +
  geom_point() +
  geom_step() +
  facet_wrap(~track, scales = "free_y") +
  scale_shape_manual(values = c(16,1)) +
  theme_minimal() +
  labs(x = "Date of Record", y = "Time to Complete (s)")
```

## When were shortcuts discovered?

I'll bring this question up the list as we can show this visually too. We see a much different situation here than in Figure 1, with decreases being a lot more "step-change-y". It is clear where short-cuts have been found as there are big step changes - e.g., for *Rainbow Road* in 2021. If I had to guess, not every drop is a new short-cut - there are likely optimisations as you'd get in a no-short-cut record too.

```{r fig.width=10, fig.height=6, fig.cap="The evolution of three-lap, shortcut records for Mario Kart 64."}
records %>%
  filter(type == "Three Lap", shortcut == "Yes") %>%
  ggplot(aes(x = date, y = time)) +
  geom_point() +
  geom_step() +
  facet_wrap(~track, scales = "free_y") +
  scale_shape_manual(values = c(16,1)) +
  theme_minimal() +
  labs(x = "Date of Record", y = "Time to Complete (s)")
```

There's no one answer to this question, but through graphing the changes we can see a lot about how the records have developed!

## Which track is the fastest?

This is a question we can likely answer in a couple of different ways, but the approach I'd take is with `group_by` and `filter`. I'm going to group by the different types of record - three lap, single lap, shortcut and no short cut - and filter our data frame for the `min` value in each.

*Mario Raceway* is the fastest for all of the single lap records, which are interestingly shared by two players - Dan and *MR*. For the three laps, *Moo Moo Farm* has the quickest non-shortcut route, and *Wario Stadium* is quickest with shortcuts. Both of the three lap records have also been held for a pretty long time!

```{r}
records %>%
  group_by(type, shortcut) %>%
  filter(time == min(time))
```

## For which track did the world record improve the most?

We could interpret this in a few different ways, but I think the best way to interpret this is *which course was reduced by the greatest percentage since the first record was set*? To do this, I'm going to `summarise` our data by extracting the `max` and `min` from each track-type-shortcut group. It's then a case of using `mutate` to calculate the percentage decrease and `filter` to get the maximum value.

*Wario Stadium*'s three-lap short-cut record has dropped by a massive 86%! If we refer back to Figure 2, *Wario Stadium* saw a ginormous decrease right at the beginning and hasn't changed a lot since. This is the nature of finding an amazing short-cut I suppose! Looking at the non-short-cut routes the drops are 21% and 16%.

```{r}
records %>%
  group_by(track, type, shortcut) %>%
  summarise(max = max(time), 
            min = min(time),
            dec = (max - min)/max) %>%
  group_by(type, shortcut) %>%
  filter(dec == max(dec)) %>%
  arrange(dec)
```

## For how many tracks have shortcuts been discovered?

This is an interesting question because there are likely genuinely a lot of different ways to approach this to end up with the same answer! We could just look at Figures 1 and 2 and count the difference in facets, but let's imagine we haven't got access to that. I've done a double `count` instead - first we `count` the number of track-shortcut pairings, then we `count` the shortcut column. We can see there are 16 courses without short-cuts, and 12 with.

```{r}
records %>%
  count(track, shortcut) %>%
  count(shortcut)
```

## On which track does the shortcut save the most time?

Let's interpret this to be the difference between the non-short-cut and short-cut times. In other words, *how much time does using the short-cut(s) rather than not save*? To do this, I'm going to use a similar process as with previous answers, using `group_by` and `filter` and calculating a percentage decrease. I'll also calculate an absolute decrease too. The big new step is `pivot_wider`, which gets the *No* and *Yes* identifiers for the shortcuts into different columns.

Once again, our friend *Wario Stadium* has the biggest percentage drop in time, though the greatest absolute time save is in *Rainbow Road*.

```{r}
records %>%
  filter(type == "Three Lap") %>%
  select(track, shortcut, time) %>%
  group_by(track, shortcut) %>%
  filter(time == min(time)) %>%
  distinct() %>%
  pivot_wider(names_from = shortcut, values_from = time) %>%
  drop_na() %>%
  mutate(abs = No - Yes,
         dec = (No - Yes)/No) %>%
  arrange(desc(dec)) %>%
  DT::datatable(options = list(pageLength = 12))
```

## Which is the longest standing world record?

We can quite straightforwardly find the longest standing world record using approaches we've already employed. It is Alex G's three-lap short-cut record for *Yoshi Valley*, which has stood since 2010, lasted 33 seconds and has yet to be defeated!

```{r}

records %>%
  filter(record_duration == max(record_duration))

```

## Who is the player with the most world records?

We could, again, just use `filter()` to determine the answer, but let's see it in context by answering this with a visualisation. `fct_reorder` let's us turn the player names into a factor, ordered by their total records. *Penev* is clearly a Mario Kart 64 machine, with 344 records!

```{r fig.cap="Mario Kart 64 Speedrunners with greater than 10 world records."}
drivers %>%
  distinct(player, total) %>%
  filter(total >= 10) %>%
  mutate(player = fct_reorder(player, total)) %>%
  ggplot(aes(y = player, x = total)) +
  geom_col(aes(fill = total), show.legend = F) +
  geom_text(aes(label = total), nudge_x = 10, vjust = .5) +
  theme_minimal() +
  labs(x = "Total Number of World Records in Mario Kart 64", y = NULL)
```

## Who are recent players?

This final question is asking who the new kids on the block are. I think we could make another cool visualisation of this. I start by finding the `distinct` (unique) combinations of player, year, and the number of records. I drop missing values so I only have the years where the players actually achieved world records, and then `filter` to find the minimum year of this new data frame. This effectively gives us a data frame of the years each player became active on the scene.

```{r fig.cap="The number of new Mario Kart 64 speedrunners per year."}
earliest_drivers = drivers %>%
  distinct(player, year, records) %>%
  drop_na() %>%
  group_by(player) %>%
  filter(year == min(year)) %>%
  ungroup()

earliest_drivers %>%
  count(year) %>%
  ggplot(aes(x = year, y = n)) +
  geom_col() +
  labs(y = "Number of New Speedrunners", x = "Year") +
  theme_minimal()
```

There was a bit of an explosion in 2020 after a slight lull in new talent. Let's find out who these new racers are:

```{r}
earliest_drivers %>%
  filter(year >= 2020) %>%
  pull(player) %>%
  paste(collapse = ", ")
```

# Closing

When you've been presented with a new data set, it can be overwhelming and difficult to think of a question to answer. Thanks very much Benedickt for easing us in with some nice data challenges to get our teeth into! Here I've used a tidyverse approach to solve every problem, but I'm sure there are a lot of different ways to tackle these questions. 

There's also, of course, no need to stop at just these questions, so I look forward to seeing loads of exciting visualisations and analysis for this week's TidyTuesday!