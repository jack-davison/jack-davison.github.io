[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am an Air Quality Measurements Data Analyst and R Developer working for an Environmental Consultancy in Oxfordshire, UK. My main role is the development of R-based tools (dynamic documents, Shiny apps, packages, etc.), and in publicising the potential applications of R within the practice.\nI was awarded a PhD in Atmospheric Chemistry, having studied in the Wolfson Atmospheric Chemistry Laboratories at the University of York, UK. My main research interests were in the remote measurements and modelling of road transport exhaust emissions.\nI’ve been using and refining my R skills over the past five years, with particular attention to the Tidyverse suite of R packages and the openair family for air quality data analysis.\nI have contributed to the #TidyTuesday Project since Summer 2020. My submissions can be found on my GitHub or Twitter.\nIn 2021, I became an RStudio Certified Tidyverse Instructor."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "We’ve got R at home",
    "section": "",
    "text": "rvest\n\n\nwebscraping\n\n\n\n\nOvercoming the lack of a “filter” option on an experience booking website through web scraping.\n\n\n\n\n\n\nNov 13, 2022\n\n\nJack Davison\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntidytuesday\n\n\n\n\nA disucssion on data tidying and cleaning, with applications to a messy, unfamiliar data set.\n\n\n\n\n\n\nFeb 2, 2021\n\n\nJack Davison\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-02-02-tidytuesday-2021-week-6-hbcu-enrollment-an-ode-to-data-cleaning/index.html#what-are-the-issues",
    "href": "posts/2021-02-02-tidytuesday-2021-week-6-hbcu-enrollment-an-ode-to-data-cleaning/index.html#what-are-the-issues",
    "title": "An Ode to Data Tidying (TidyTuesday 2021 Week 6: HBCU Enrolment)",
    "section": "What are the issues?",
    "text": "What are the issues?\nLet’s read in the data and give it a look over.\nThe bach_students data set indicates…\n\nThe percentage of students broken down by race/ethnicity, aged 25 and over who have attained a bachelor’s degree.\n\nBut in the form it is in, it is pretty untidy and unclean. Here are some issues I can identify:\n\nOur key variables are effectively year, race, total and standard error, but race is spread over multiple columns (remember - each column should represent a variable, not multiple columns representing one variable).\nAll of the columns should be numbers, but they have read in as characters.\nAsian people and Pacific Islanders are given twice - as a total of the two and individually.\nThe names of the columns have spaces in them, are wordy and therefore generally difficult to use.\nThe Total column represents the year. The name is therefore a bit misleading.\n\nA note on the emboldened item above; in my experience, data “in the wild” that has been put together in Excel typically has baggage like this as spreadsheets are sadly used for both data storage and presentation. This means that totals and the like are given alongside the data used to calculate them. I don’t feel bad about removing data like this as long as we are left with the tools to recalculate them. In this case, we are! If we want to regroup the Asian/Pacific Islander data it’d be as easy as renaming them both as the same thing using mutate() and if_else(), and then group_by() and summarise() to re-calculate the total. It may even be that we want to combine more racial groups using a fct_lump() function."
  },
  {
    "objectID": "posts/2021-02-02-tidytuesday-2021-week-6-hbcu-enrollment-an-ode-to-data-cleaning/index.html#cleaning-and-tidying",
    "href": "posts/2021-02-02-tidytuesday-2021-week-6-hbcu-enrollment-an-ode-to-data-cleaning/index.html#cleaning-and-tidying",
    "title": "An Ode to Data Tidying (TidyTuesday 2021 Week 6: HBCU Enrolment)",
    "section": "Cleaning and Tidying",
    "text": "Cleaning and Tidying\nLet’s start by making sure that all of the data is numeric. dplyr v1.0.0 gave us the across() function that makes this a breeze.\n\nbach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  head(16)\n\n# A tibble: 16 × 19\n   Total `Total, percent of al…` `Standard Erro…` White1 `Standard Erro…` Black1\n   <dbl>                   <dbl>            <dbl>  <dbl>            <dbl>  <dbl>\n 1  1910                     2.7            NA      NA              NA      NA  \n 2  1920                     3.3            NA      NA              NA      NA  \n 3  1930                     3.9            NA      NA              NA      NA  \n 4  1940                     4.6            NA       4.9            NA       1.3\n 5  1950                     6.2            NA       6.6            NA       2.2\n 6  1960                     7.7            NA       8.1            NA       3.5\n 7  1970                    11              NA      11.6            NA       6.1\n 8  1975                    13.9            NA      14.9            NA       6.4\n 9  1980                    17              -0.16   18.4            -0.18    7.9\n10  1985                    19.4            -0.16   20.8            -0.19   11.1\n11  1986                    19.4            -0.16   20.9            -0.19   10.9\n12  1987                    19.9            -0.16   21.4            -0.19   10.8\n13  1988                    20.3            -0.16   21.8            -0.19   11.2\n14  1989                    21.1            -0.16   22.8            -0.19   11.7\n15  1990                    21.3            -0.16   23.1            -0.19   11.3\n16  1991                    21.4            -0.16   23.3            -0.19   11.5\n# … with 13 more variables: `Standard Errors - Black1` <dbl>, Hispanic <dbl>,\n#   `Standard Errors - Hispanic` <dbl>, `Total - Asian/Pacific Islander` <dbl>,\n#   `Standard Errors - Total - Asian/Pacific Islander` <dbl>,\n#   `Asian/Pacific Islander - Asian` <dbl>,\n#   `Standard Errors - Asian/Pacific Islander - Asian` <dbl>,\n#   `Asian/Pacific Islander - Pacific Islander` <dbl>,\n#   `Standard Errors - Asian/Pacific Islander - Pacific Islander` <dbl>, …\n\n\nWe could be tempted now to run janitor::clean_names(). For those unfamiliar, this function cleans the names of a data frame to make them easier to use - all lower-case, spaces replaced with underscores, and the like. Normally it’s a good idea to use it as soon as possible, but as I am going to restructure my data I am not going to use it right away. As race will be one of my columns, I’d probably want words like “White” and “Black” to remain capitalised, so if I reported them in a table or use them in a legend label they’d look more presentable.\nNext, we can start restructuring. A good trick with pivot_longer() is that it behaves much the same as functions like select() - if we list a column name preceded with a minus sign (-) it effectively tells the function “everything but this column, please!” I’m not going to specify column names for the names or values here as we’ll quickly get rid of them.\n\nbach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  pivot_longer(-Total) %>% \n  head(16)\n\n# A tibble: 16 × 3\n   Total name                                                              value\n   <dbl> <chr>                                                             <dbl>\n 1  1910 \"Total, percent of all persons age 25 and over\"                     2.7\n 2  1910 \"Standard Errors - Total, percent of all persons age 25 and over\"  NA  \n 3  1910 \"White1\"                                                           NA  \n 4  1910 \"Standard Errors - White1\"                                         NA  \n 5  1910 \"Black1\"                                                           NA  \n 6  1910 \"Standard Errors - Black1\"                                         NA  \n 7  1910 \"Hispanic\"                                                         NA  \n 8  1910 \"Standard Errors - Hispanic\"                                       NA  \n 9  1910 \"Total - Asian/Pacific Islander\"                                   NA  \n10  1910 \"Standard Errors - Total - Asian/Pacific Islander\"                 NA  \n11  1910 \"Asian/Pacific Islander - Asian\"                                   NA  \n12  1910 \"Standard Errors - Asian/Pacific Islander - Asian\"                 NA  \n13  1910 \"Asian/Pacific Islander - Pacific Islander\"                        NA  \n14  1910 \"Standard Errors - Asian/Pacific Islander - Pacific Islander\"      NA  \n15  1910 \"American Indian/\\r\\nAlaska Native\"                                NA  \n16  1910 \"Standard Errors - American Indian/\\r\\nAlaska Native\"              NA  \n\n\nNow we can remove that Asian/Pacific Islander total we spoke about earlier. We will use filter() alongside the str_detect() function and the logical operator !.\n\nbach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  pivot_longer(-Total) %>%\n  filter(!str_detect(name, \"Total - Asian/Pacific Islander\")) %>%\n  head(16)\n\n# A tibble: 16 × 3\n   Total name                                                              value\n   <dbl> <chr>                                                             <dbl>\n 1  1910 \"Total, percent of all persons age 25 and over\"                     2.7\n 2  1910 \"Standard Errors - Total, percent of all persons age 25 and over\"  NA  \n 3  1910 \"White1\"                                                           NA  \n 4  1910 \"Standard Errors - White1\"                                         NA  \n 5  1910 \"Black1\"                                                           NA  \n 6  1910 \"Standard Errors - Black1\"                                         NA  \n 7  1910 \"Hispanic\"                                                         NA  \n 8  1910 \"Standard Errors - Hispanic\"                                       NA  \n 9  1910 \"Asian/Pacific Islander - Asian\"                                   NA  \n10  1910 \"Standard Errors - Asian/Pacific Islander - Asian\"                 NA  \n11  1910 \"Asian/Pacific Islander - Pacific Islander\"                        NA  \n12  1910 \"Standard Errors - Asian/Pacific Islander - Pacific Islander\"      NA  \n13  1910 \"American Indian/\\r\\nAlaska Native\"                                NA  \n14  1910 \"Standard Errors - American Indian/\\r\\nAlaska Native\"              NA  \n15  1910 \"Two or more race\"                                                 NA  \n16  1910 \"Standard Errors - Two or more race\"                               NA  \n\n\nTo separate the total values from the standard errors we can use the separate() function and the \" - \" string. Issues once again come from the Asian and Pacific Islander data as they have a second \" - \" in them, but this can be straightforwardly removed. For whatever reason, “White” and “Black” are listed with the number one (1) after them, so we can get rid of this while we’re on the subject of cleaning strings.\n\nbach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  pivot_longer(-Total) %>%\n  filter(!str_detect(name, \"Total - Asian/Pacific Islander\")) %>%\n  mutate(name = str_remove(name, \"Asian/Pacific Islander - |1\")) %>%\n  head(16)\n\n# A tibble: 16 × 3\n   Total name                                                              value\n   <dbl> <chr>                                                             <dbl>\n 1  1910 \"Total, percent of all persons age 25 and over\"                     2.7\n 2  1910 \"Standard Errors - Total, percent of all persons age 25 and over\"  NA  \n 3  1910 \"White\"                                                            NA  \n 4  1910 \"Standard Errors - White\"                                          NA  \n 5  1910 \"Black\"                                                            NA  \n 6  1910 \"Standard Errors - Black\"                                          NA  \n 7  1910 \"Hispanic\"                                                         NA  \n 8  1910 \"Standard Errors - Hispanic\"                                       NA  \n 9  1910 \"Asian\"                                                            NA  \n10  1910 \"Standard Errors - Asian\"                                          NA  \n11  1910 \"Pacific Islander\"                                                 NA  \n12  1910 \"Standard Errors - Pacific Islander\"                               NA  \n13  1910 \"American Indian/\\r\\nAlaska Native\"                                NA  \n14  1910 \"Standard Errors - American Indian/\\r\\nAlaska Native\"              NA  \n15  1910 \"Two or more race\"                                                 NA  \n16  1910 \"Standard Errors - Two or more race\"                               NA  \n\n\nNow let’s add that separate() step, which we need to give some column names for the name column to turn into, the separating character (space-dash-space), and the direction to fill in (in this case left).\n\nbach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  pivot_longer(-Total) %>%\n  filter(!str_detect(name, \"Total - Asian/Pacific Islander\")) %>%\n  mutate(name = str_remove(name, \"Asian/Pacific Islander - |1\")) %>%\n  separate(name, into = c(\"stat\",\"race\"), sep = \" - \", fill = \"left\") %>%\n  head(16)\n\n# A tibble: 16 × 4\n   Total stat            race                                            value\n   <dbl> <chr>           <chr>                                           <dbl>\n 1  1910 <NA>            \"Total, percent of all persons age 25 and over\"   2.7\n 2  1910 Standard Errors \"Total, percent of all persons age 25 and over\"  NA  \n 3  1910 <NA>            \"White\"                                          NA  \n 4  1910 Standard Errors \"White\"                                          NA  \n 5  1910 <NA>            \"Black\"                                          NA  \n 6  1910 Standard Errors \"Black\"                                          NA  \n 7  1910 <NA>            \"Hispanic\"                                       NA  \n 8  1910 Standard Errors \"Hispanic\"                                       NA  \n 9  1910 <NA>            \"Asian\"                                          NA  \n10  1910 Standard Errors \"Asian\"                                          NA  \n11  1910 <NA>            \"Pacific Islander\"                               NA  \n12  1910 Standard Errors \"Pacific Islander\"                               NA  \n13  1910 <NA>            \"American Indian/\\r\\nAlaska Native\"              NA  \n14  1910 Standard Errors \"American Indian/\\r\\nAlaska Native\"              NA  \n15  1910 <NA>            \"Two or more race\"                               NA  \n16  1910 Standard Errors \"Two or more race\"                               NA  \n\n\nYou’ll notice that in the stats column we have some NA values that actually correspond to the “total” stat, so we’ll fill those in using a tidyr function, replace_na().\n\nbach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  pivot_longer(-Total) %>%\n  filter(!str_detect(name, \"Total - Asian/Pacific Islander\")) %>%\n  mutate(name = str_remove(name, \"Asian/Pacific Islander - |1\")) %>%\n  separate(name, into = c(\"stat\",\"race\"), sep = \" - \", fill = \"left\") %>%\n  mutate(stat = replace_na(stat, \"Total\")) %>%\n  head(16)\n\n# A tibble: 16 × 4\n   Total stat            race                                            value\n   <dbl> <chr>           <chr>                                           <dbl>\n 1  1910 Total           \"Total, percent of all persons age 25 and over\"   2.7\n 2  1910 Standard Errors \"Total, percent of all persons age 25 and over\"  NA  \n 3  1910 Total           \"White\"                                          NA  \n 4  1910 Standard Errors \"White\"                                          NA  \n 5  1910 Total           \"Black\"                                          NA  \n 6  1910 Standard Errors \"Black\"                                          NA  \n 7  1910 Total           \"Hispanic\"                                       NA  \n 8  1910 Standard Errors \"Hispanic\"                                       NA  \n 9  1910 Total           \"Asian\"                                          NA  \n10  1910 Standard Errors \"Asian\"                                          NA  \n11  1910 Total           \"Pacific Islander\"                               NA  \n12  1910 Standard Errors \"Pacific Islander\"                               NA  \n13  1910 Total           \"American Indian/\\r\\nAlaska Native\"              NA  \n14  1910 Standard Errors \"American Indian/\\r\\nAlaska Native\"              NA  \n15  1910 Total           \"Two or more race\"                               NA  \n16  1910 Standard Errors \"Two or more race\"                               NA  \n\n\nNow we can pivot_wider() to get the total values and the standard errors in their own columns. We’ll have to rename the existing Total column first, but that can be achieved using dplyr’s rename().\n\nbach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  pivot_longer(-Total) %>%\n  filter(!str_detect(name, \"Total - Asian/Pacific Islander\")) %>%\n  mutate(name = str_remove(name, \"Asian/Pacific Islander - |1\")) %>%\n  separate(name, into = c(\"stat\",\"race\"), sep = \" - \", fill = \"left\") %>%\n  mutate(stat = replace_na(stat, \"Total\")) %>%\n  rename(year = Total) %>%\n  pivot_wider(names_from = stat, values_from = value) %>%\n  head(8)\n\n# A tibble: 8 × 4\n   year race                                            Total `Standard Errors`\n  <dbl> <chr>                                           <dbl>             <dbl>\n1  1910 \"Total, percent of all persons age 25 and over\"   2.7                NA\n2  1910 \"White\"                                          NA                  NA\n3  1910 \"Black\"                                          NA                  NA\n4  1910 \"Hispanic\"                                       NA                  NA\n5  1910 \"Asian\"                                          NA                  NA\n6  1910 \"Pacific Islander\"                               NA                  NA\n7  1910 \"American Indian/\\r\\nAlaska Native\"              NA                  NA\n8  1910 \"Two or more race\"                               NA                  NA\n\n\nThe data is now tidy! We can do some additional cleaning steps now - there seems to be something odd going on with the American Indian/Alaska Native string, and the “Total” string is a bit wordy. Let’s sort that out, and finally throw in that janitor function I talked about right at the beginning.\n\ndf = bach_students %>%\n  mutate(across(.cols = where(is.character), \n                .fns = parse_number)) %>%\n  pivot_longer(-Total) %>%\n  filter(!str_detect(name, \"Total - Asian/Pacific Islander\")) %>%\n  mutate(name = str_remove(name, \"Asian/Pacific Islander - |1\")) %>%\n  separate(name, into = c(\"stat\",\"race\"), sep = \" - \", fill = \"left\") %>%\n  mutate(stat = replace_na(stat, \"Total\")) %>%\n  rename(year = Total) %>%\n  pivot_wider(names_from = stat, values_from = value) %>%\n  janitor::clean_names() %>%\n  mutate(\n    race = str_remove_all(\n      race, \n      \", percent of all persons age 25 and over|\\r\\n\")\n  )\n\ndf %>% head(8)\n\n# A tibble: 8 × 4\n   year race                          total standard_errors\n  <dbl> <chr>                         <dbl>           <dbl>\n1  1910 Total                           2.7              NA\n2  1910 White                          NA                NA\n3  1910 Black                          NA                NA\n4  1910 Hispanic                       NA                NA\n5  1910 Asian                          NA                NA\n6  1910 Pacific Islander               NA                NA\n7  1910 American Indian/Alaska Native  NA                NA\n8  1910 Two or more race               NA                NA\n\n\nWe did it! The data is now clean and tidy and ready to use. Let’s do a bit of analysis just to demonstrate how straightforward it is to use now."
  },
  {
    "objectID": "posts/2021-02-02-tidytuesday-2021-week-6-hbcu-enrollment-an-ode-to-data-cleaning/index.html#data-analysis",
    "href": "posts/2021-02-02-tidytuesday-2021-week-6-hbcu-enrollment-an-ode-to-data-cleaning/index.html#data-analysis",
    "title": "An Ode to Data Tidying (TidyTuesday 2021 Week 6: HBCU Enrolment)",
    "section": "Data Analysis",
    "text": "Data Analysis\nWe can create some cool plots now we have access to this data. We can start with a simple timeseries.\n\ntheme_set(theme_light())\n\nplot_data = df %>%\n  drop_na() %>%\n  mutate(across(total:standard_errors, ~.x/100))\n\nplot_data %>%\n  filter(race != \"Total\") %>%\n  mutate(race = fct_reorder(race, total, max, na.rm = T),\n         race = fct_rev(race)) %>%\n  ggplot(aes(\n    year,\n    y = total,\n    ymax = total + standard_errors,\n    ymin = total - standard_errors,\n    group = race\n  )) +\n  geom_ribbon(aes(fill = race), alpha = .25) +\n  geom_line(aes(color = race)) +\n  geom_line(data = filter(plot_data, race == \"Total\"), size = 2) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(x = \"Year\", y = NULL, color = \"Race\", fill = \"Race\",\n       title = \"Bachelor's Degree Attainment\",\n       subtitle = \"The percentage of the population who have achieved a\\nbachelor's degree in the US since 1980, split into racial groups.\\nThe bold line represents the total population.\") +\n  theme(plot.title.position = \"plot\")\n\n\n\n\nOr we could just focus in on the most recent data.\n\nplot_data_2 = plot_data %>%\n  filter(year == max(year)) %>%\n  mutate(race = fct_reorder(race, total))\n\ntot = plot_data_2 %>%\n  filter(race == \"Total\") %>% \n  pull(total)\n\nplot_data_2 %>%\n  mutate(flag = case_when(race == \"Total\" ~ \"T\",\n                          total > tot ~ \"Y\",\n                          total < tot ~ \"X\")) %>%\n  ggplot(aes(y = race, x = total, xmax = total+standard_errors, xmin = total-standard_errors, fill = flag)) +\n  geom_col(show.legend = F) +\n  geom_vline(xintercept = tot, size = 1) +\n  geom_pointrange(show.legend = F) +\n  scale_x_continuous(expand = expansion(mult = c(0,.1)), \n                     labels = scales::percent) +\n  labs(y = NULL, x = \"Bachelor's Degree Attainment in 2016\")\n\n\n\n\n\nplot_data_2 %>%\n  janitor::remove_constant() %>%\n  mutate(mutate(across(\n    where(is.numeric), ~ glue::glue(\"{abs(.x) * 100} %\")\n  ))) %>%\n  knitr::kable(col.names = c(\"Race\", \"Total\", \"Std Err.\")) %>%\n  kableExtra::kable_styling()\n\n\n\n\n Race \n    Total \n    Std Err. \n  \n\n\n Total \n    33.4 % \n    0.24 % \n  \n\n White \n    37.3 % \n    0.31 % \n  \n\n Black \n    23.5 % \n    0.46 % \n  \n\n Hispanic \n    16.4 % \n    0.4 % \n  \n\n Asian \n    56.4 % \n    0.89 % \n  \n\n Pacific Islander \n    27.5 % \n    2.92 % \n  \n\n American Indian/Alaska Native \n    16.8 % \n    1.39 % \n  \n\n Two or more race \n    30.6 % \n    1.52 % \n  \n\n\n\n\nSee how easy it is to use this data now? Incredible!"
  },
  {
    "objectID": "posts/2022-11-13-pastaEvangelists/index.html",
    "href": "posts/2022-11-13-pastaEvangelists/index.html",
    "title": "Scraping the Pasta Academy",
    "section": "",
    "text": "Purpose\nRecently, my partner and I were looking to book a cooking experience as a Christmas treat, and we settled on the excellently reviewed Pasta Academy in London. We were looking for a beginner class in early 2023, but we were immediately met with an issue — there was no way to filter the booking list!\nWe could have sat and go through the list manually, perhaps noting down each of the beginner classes when we found them. This sounded like a bit of a faff, so I instead thought I’d scrape all of the courses and put them into a table. Some might argue that writing an R script to do this is even more of a faff, but I did it anyway!\nThis blog post shows how I scraped the data from the Pasta Academy website using rvest and then went on to tidy it using the tidyverse. You may find this a nice introduction to web scraping in R, and a nice application of data skills in “real life”.\nWeb Scraping with {rvest}\n\n\nlibrary(rvest)\nlibrary(tidyverse)\n\nWe’ll start by scraping the first page. To start using rvest, we first need to define a session. This simulates a user interacting with a website.\n\npasta_session <-\n  session(\"https://pastaevangelists.com/collections/pasta-academy?page=1\")\n\nWe’ll now need to pull each individual element of interest from the Pasta Academy website. One of the easiest ways of finding the correct HTML at which to aim your rvest functions is by using Chrome’s developer tools (CTRL-SHIFT-I on Windows) or your browser’s equivalent.\n\n\nFigure 1: A screenshot of the use of Chrome’s developer tools.\n\n\nOnce we have identified the correct HTML tags to use, we can use html_elements() to grab those items, and then html_text2() to extract the text from it. For example, the below line grabs each lesson title from the first page of the Pasta Academy website.\n\nhtml_elements(pasta_session, \".product-item-row__meta-title\") |> html_text2()\n\n [1] \"TASTE OF CALABRIA | APERITIVO SPECIAL WITH ITALICUS |\\r\"                       \n [2] \"PASTA ACADEMY™ | TASTE OF NAPOLI |\\r\"                                          \n [3] \"PASTA ACADEMY™ | PASTA BEGINNERS CLASS |\\r\"                                    \n [4] \"PASTA ACADEMY™ | TASTE OF ROME |\\r\"                                            \n [5] \"PASTA ACADEMY™ | BEGINNERS FILLED PASTA with Sofia (as seen on Masterchef) |\\r\"\n [6] \"PASTA ACADEMY™ | FESTIVE TASTE OF SARDINIA |\\r\"                                \n [7] \"PASTA EVANGELISTS & LAYLO WINES | PASTA MAKING & WINE TASTING |\\r\"             \n [8] \"PASTA ACADEMY™ | FESTIVE TASTE OF TUSCANY ?? |\\r\"                              \n [9] \"PASTA ACADEMY™ | TASTE OF LIGURIA WITH HEAD CHEF ROBERTA|\\r\"                   \n[10] \"PASTA ACADEMY™ | FESTIVE TASTE OF EMILIA-ROMAGNA |\\r\"                          \n[11] \"PASTA ACADEMY™ | FESTIVE PASTA BEGINNERS CLASS |\\r\"                            \n[12] \"PASTA ACADEMY™ | FESTIVE TASTE OF EMILIA-ROMAGNA |\\r\"                          \n\n\nAll we need to do is repeat this until we have all of the information we want. In this case, all I need is the course title, the date/time, the price, and whether or not it is sold out. The button text is a useful proxy for that last item, as it reads “SEE INFO” if a course is fully booked and “BOOK NOW” if there are spaces left.\n\nname <- html_elements(pasta_session, \".product-item-row__meta-title\") |> html_text2()\n\ndate <- html_elements(pasta_session, \".product-item-row__meta-title-sub\") |> html_text2()\n\nprice <- html_elements(pasta_session, \"span.price\") |> html_text2()\n\nbutton <- html_elements(pasta_session, \".product-item-row__cta-btn\") |> html_text2()\n\ndplyr::tibble(\n  name = name, \n  date = date,\n  price = price, \n  button = button\n) |>\n  dplyr::glimpse()\n\nRows: 12\nColumns: 4\n$ name   <chr> \"TASTE OF CALABRIA | APERITIVO SPECIAL WITH ITALICUS |\\r\", \"PAS…\n$ date   <chr> \"\\r Friday 11th November 2022, 18:30\\r\", \"\\r Saturday 12th Nove…\n$ price  <chr> \"£60.00\\r\", \"£50.00\\r\", \"£50.00\\r\", \"£50.00\\r\", \"£60.00\\r\", \"£6…\n$ button <chr> \"SEE INFO\", \"SEE INFO\", \"BOOK NOW\", \"SEE INFO\", \"SEE INFO\", \"SE…\n\n\nNow all four pieces of information can be scraped from one page, we can use purrr to scrape this information from all of the pages. We’ll write a function which takes one argument, id, which is used to select the specific page of the Pasta Academy website.\n\nscrape_pasta <- function(id){\n  x <- session(str_glue(\"https://pastaevangelists.com/collections/pasta-academy?page={id}\"))\n  \n  tibble(\n    name = html_elements(x, \".product-item-row__meta-title\") |> html_text2(),\n    date = html_elements(x, \".product-item-row__meta-title-sub\") |> html_text2(),\n    price = html_elements(x, \"span.price\") |> html_text2(),\n    fully_booked = html_elements(x, \".product-item-row__cta-btn\") |> html_text2()\n  ) |>\n    mutate(page_id = id)\n}\n\nraw_pasta <- map_dfr(1:19, scrape_pasta)\n\nTidying Data\nWe wouldn’t eat raw pasta, and we won’t want to work with raw_pasta as it currently exists. Lets use the tidyverse to tidy this data up a bit.\nFirst, lets get rid of some of the dodgy formatting — we’ll drop the \\r, vertical bars, question marks, and the PASTA ACADEMY branding from all character columns.\n\npasta <- \n  raw_pasta |>\n  mutate(across(where(is.character), \n                ~ str_remove_all(.x, \"PASTA ACADEMY™|\\r|\\\\||\\\\?\") |> \n                  str_squish()))\npasta\n\n# A tibble: 224 × 5\n   name                                              date  price fully…¹ page_id\n   <chr>                                             <chr> <chr> <chr>     <int>\n 1 TASTE OF CALABRIA APERITIVO SPECIAL WITH ITALICUS Frid… £60.… SEE IN…       1\n 2 TASTE OF NAPOLI                                   Satu… £50.… SEE IN…       1\n 3 PASTA BEGINNERS CLASS                             Satu… £50.… BOOK N…       1\n 4 TASTE OF ROME                                     Sund… £50.… SEE IN…       1\n 5 BEGINNERS FILLED PASTA with Sofia (as seen on Ma… Sund… £60.… SEE IN…       1\n 6 FESTIVE TASTE OF SARDINIA                         Sund… £60.… SEE IN…       1\n 7 PASTA EVANGELISTS & LAYLO WINES PASTA MAKING & W… Tues… £60.… SEE IN…       1\n 8 FESTIVE TASTE OF TUSCANY                          Wedn… £60.… SEE IN…       1\n 9 TASTE OF LIGURIA WITH HEAD CHEF ROBERTA           Frid… £60.… SEE IN…       1\n10 FESTIVE TASTE OF EMILIA-ROMAGNA                   Satu… £60.… SEE IN…       1\n# … with 214 more rows, and abbreviated variable name ¹​fully_booked\n\n\nAn easier step — lets format the price as numeric data, and fully_booked as logical. Lets also make name all lower-case.\n\npasta <-\n  pasta |> \n  mutate(name = tolower(name),\n         price = parse_number(price),\n         fully_booked = if_else(fully_booked == \"SEE INFO\", T, F))\n\npasta\n\n# A tibble: 224 × 5\n   name                                              date  price fully…¹ page_id\n   <chr>                                             <chr> <dbl> <lgl>     <int>\n 1 taste of calabria aperitivo special with italicus Frid…    60 TRUE          1\n 2 taste of napoli                                   Satu…    50 TRUE          1\n 3 pasta beginners class                             Satu…    50 FALSE         1\n 4 taste of rome                                     Sund…    50 TRUE          1\n 5 beginners filled pasta with sofia (as seen on ma… Sund…    60 TRUE          1\n 6 festive taste of sardinia                         Sund…    60 TRUE          1\n 7 pasta evangelists & laylo wines pasta making & w… Tues…    60 TRUE          1\n 8 festive taste of tuscany                          Wedn…    60 TRUE          1\n 9 taste of liguria with head chef roberta           Frid…    60 TRUE          1\n10 festive taste of emilia-romagna                   Satu…    60 TRUE          1\n# … with 214 more rows, and abbreviated variable name ¹​fully_booked\n\n\nIt’d be useful to have the date as a properly formatted date-time column. Sadly, this column is not consistently formatted. The two issues are:\n\nSometimes the time has a comma before it, but not always\nSometimes the year is present, but not always\n\nTo deal with this, we’ll take the following steps:\n\nExtract the time & year from the date using regex.\nFill any missing years. This might not be perfect if there are missing years between December and January, but for our purposes we can live with this and can cross-reference with page_id if we need to double check.\nReformat the date by performing string transformations.\nParse the date as a date-time using lubridate.\n\nIn practice, this looks like this:\n\npasta <-\n  pasta |>\n  \n  # extract year/time\n  mutate(\n    time = str_extract(date, \"[0-9][0-9]:[0-9][0-9]\"),\n    year = str_extract(date, \"[0-9][0-9][0-9][0-9]\")\n  ) |>\n  \n  # fill year\n  fill(year, .direction = \"down\") |>\n  \n  # reformat date \n  mutate(date = str_remove_all(date, time) |>\n           str_remove_all(year) |>\n           str_remove(\", \") |>\n           str_squish() |> \n           str_remove(\", am\")) |> \n  separate(date, c(\"day\", \"date\"), sep = \" \", extra = \"merge\") |> \n  unite(date, date, year, time, sep = \" \") |> \n  mutate(date = str_remove(date, \",\")) |> \n  \n  # parse date as date-time\n  mutate(date = lubridate::parse_date_time(date, \n                                           orders = c(\"BdY HM\", \"dBY HM\"))) |>\n  \n  # drop date\n  select(-day)\n\npasta\n\n# A tibble: 224 × 5\n   name                                date                price fully…¹ page_id\n   <chr>                               <dttm>              <dbl> <lgl>     <int>\n 1 taste of calabria aperitivo specia… 2022-11-11 18:30:00    60 TRUE          1\n 2 taste of napoli                     2022-11-12 13:00:00    50 TRUE          1\n 3 pasta beginners class               2022-11-12 18:30:00    50 FALSE         1\n 4 taste of rome                       2022-11-13 18:30:00    50 TRUE          1\n 5 beginners filled pasta with sofia … 2022-11-13 13:00:00    60 TRUE          1\n 6 festive taste of sardinia           2022-11-20 13:00:00    60 TRUE          1\n 7 pasta evangelists & laylo wines pa… 2022-11-15 18:30:00    60 TRUE          1\n 8 festive taste of tuscany            2022-11-16 18:30:00    60 TRUE          1\n 9 taste of liguria with head chef ro… 2022-11-18 18:30:00    60 TRUE          1\n10 festive taste of emilia-romagna     2022-11-19 13:00:00    60 TRUE          1\n# … with 214 more rows, and abbreviated variable name ¹​fully_booked\n\n\nUsing the data\nNow that the data is in a tidy format, lets find out when the available beginner courses are being held. Evenings are also our preference:\n\npotential_classes <- \n  pasta |> \n  filter(str_detect(name, \"beg\"),\n         lubridate::hour(date) > 14,\n         !fully_booked)\n\npotential_classes\n\n# A tibble: 22 × 5\n   name                           date                price fully_booked page_id\n   <chr>                          <dttm>              <dbl> <lgl>          <int>\n 1 pasta beginners class          2022-11-12 18:30:00    50 FALSE              1\n 2 beginners class                2022-12-18 18:30:00    65 FALSE              4\n 3 festive beginners filled pasta 2022-12-23 18:30:00    65 FALSE              5\n 4 beginners class                2022-12-29 18:30:00    65 FALSE              5\n 5 beginners class                2023-01-15 18:30:00    65 FALSE              6\n 6 beginners class                2023-01-31 18:30:00    65 FALSE              8\n 7 beginners class                2023-02-05 18:30:00    65 FALSE              8\n 8 beginners class                2023-02-17 18:30:00    65 FALSE              9\n 9 beginners class                2023-02-26 18:30:00    65 FALSE             10\n10 beginners class                2023-03-11 18:30:00    65 FALSE             11\n# … with 12 more rows\n\n\nAnd there they are!\nJust as we now have the data to hand, lets see what some common themes are in the classes. Disregarding words that aren’t particularly unique or descriptive like “taste”, “beginners”, “class”, “morning”, we can learn that there seems to be a lot of festive classes, and those inspired by the cuisines of Rome, Tuscany and Sardinia.\n\npasta |> \n  tidytext::unnest_tokens(word, name) |> \n  anti_join(tidytext::get_stopwords()) |> \n  count(word, sort = T)\n\n# A tibble: 49 × 2\n   word          n\n   <chr>     <int>\n 1 taste       135\n 2 beginners    78\n 3 class        45\n 4 morning      31\n 5 festive      29\n 6 pasta        23\n 7 rome         21\n 8 tuscany      18\n 9 chef         16\n10 sardinia     16\n# … with 39 more rows\n\n\nFigure 2 reveals that (unsurprisingly) festive classes are all before January, but the other three common themes are spaced out regularly throughout the year.\n\npasta |>\n  tidytext::unnest_tokens(word, name) |>\n  filter(word %in% c(\"rome\", \"tuscany\", \"sardinia\", \"festive\")) |>\n  ggplot(aes(x = date)) +\n  geom_histogram(aes(fill = word)) +\n  theme_bw() +\n  theme(legend.position = \"top\") +\n  labs(x = NULL, fill = NULL) +\n  scale_y_continuous(expand = expansion(mult = c(0, .1)))\n\n\n\nFigure 2: Distribution of common classes throughout the year."
  }
]